\subsection{Exploratory Data Analysis}
The Exploratory Data Analysis in this project is separated into two parts: The first part (implemented in the quantlet \textit{Exploratory\_Data\_Analysis.R}) concentrates on the univariate analysis of the target variable as well as some general overview of the categoric and numeric variables in the dataset, while the second part (\textit{Exploratory\_Data\_Analysis\_Dependence.R}) analyses the dependence and correlation structure between the explanatory variables and the target variable. 

\subsubsection{Exploratory Data Analysis Univariate}
The first part begins with an analysis of the distribution of the target variable \textit{SalePrice} both in its original form as well as its distribution after taking the logarithm. In both cases we create a histogram using the corresponding function from the \textit{ggplot2} package. Than we add to the plot both the empirical density function as well as the density of a normal function with mean and variance set to the empirical estimates. This is done calling  \textit{stat\_function} with the \textit{fun} parameter set to the normal density \textit{dnorm} function.
\begin{lstlisting}[language=R]
price.hist = ggplot(data, aes(x = SalePrice)) + geom_histogram(aes(y = ..density..), bins = 20, 
    colour = "black", fill = "white") + geom_density(alpha = 0.2, fill = "#FF6666") + ggtitle("Distribution of Sale Price vs. Normal Distribution") + 
    xlab("Sale Price") + stat_function(fun = dnorm, args = list(mean = mean(data$SalePrice, 
    na.rm = TRUE), sd = sd(data$SalePrice, na.rm = TRUE)), col = "blue", size = 2)
ggsave(filename = "PriceHist.pdf")
# Histogram and QQ Plot of Log Prices
logprice.hist = ggplot(data, aes(x = log(SalePrice))) + geom_histogram(aes(y = ..density..), 
    bins = 20, colour = "black", fill = "white") + geom_density(alpha = 0.2, fill = "#FF6666") + 
    ggtitle("Distribution of  Log Sale Price vs. Normal Distribution") + xlab("Log Sale Price") + 
    stat_function(fun = dnorm, args = list(mean = mean(log(data$SalePrice), na.rm = TRUE), sd = sd(log(data$SalePrice), 
        na.rm = TRUE)), col = "blue", size = 2)
ggsave(filename = "LogPriceHist.pdf")
\end{lstlisting}
After creating the histograms we furthermore create a qq-plot of the standardised log prices. For this we substract the mean from the log-SalePrice and divide by the standard deviation. Then we create the qq-plot using the corresponding function from the \textit{ggplot2} package to compare the quantiles against those of the standard normal distribution.

\begin{lstlisting}[language=R]
stdprice.qq = ggplot(data, aes(sample = (log(SalePrice) - mean(log(SalePrice), na.rm = TRUE))/sd(log(SalePrice), 
    na.rm = TRUE))) + stat_qq() + geom_abline(slope = 1, intercept = 0, col = "red") + ggtitle("QQ-Plot of Standardised Log Sale Price") + 
    xlab("Standardised Log Sale Price")
ggsave(filename = "StdPriceQQ.pdf")
\end{lstlisting}

While the qq-Plot completes the analysis of the target variable  we continue with an overview over categoric and numeric input variables. For this we first separate the data set accordingly into two datasets of numeric and categoric variables. For this we extract the column classes by applying the \textit{class} function to each column using \textit{sapply}. We then use a logical comparison of this vector as column index to generate the respective sub-datasets.
\begin{lstlisting}[language=R]
# Get Column Classes:
colclasses = sapply(data, class)
table(colclasses)

# Seperate data in numeric and categoric variables for further analysis
numeric.data = data[, names(colclasses[colclasses != "factor"])]
categoric.data = data[, names(colclasses[colclasses == "factor"])]
\end{lstlisting}
For the overview of the categoric variables we define new functions which return the most frequent factor level, the frequency of that level and the total number of unique levels for each variable. We then apply each of these functions across the columns of the categoric data set and bind the results together in one \textit{data.frame}.
\begin{lstlisting}[language=R]
# Define Functions for variable overview
getmode = function(x) {
    x = x[!is.na(x)]
    unique(x)[which.max(tabulate(match(x, unique(x))))]
}
getmodefreq = function(x) {
    mean(x == getmode(x), na.rm = TRUE)
}
getlevelcount = function(x) {
    x = x[!is.na(x)]
    length(unique(x))
}

# Create Overview table for categoric variables:
categoric.overview = data.frame(NACount = colSums(sapply(categoric.data, is.na)), LevelCount = sapply(categoric.data, 
    FUN = getlevelcount), Mode = sapply(categoric.data, FUN = getmode), ModeFrequency = sapply(categoric.data, 
    FUN = getmodefreq))
\end{lstlisting} 

For the overview over numeric variables we follow a very similar approach. However in this case we additionally calculate the mean, median and standard deviation of each variable. To be able to exclude NAs from these calculation we create new functions for these calculations which just call the original function with $na.rm$ set to TRUE.
\begin{lstlisting}[language=R]
#These are just wrappers around existing functions setting na.rm = TRUE
meanwrapper       = function(x) mean(x, na.rm = TRUE)
medianwrapper     = function(x) median(x, na.rm = TRUE)
sdwrapper         = function(x) sd(x, na.rm = TRUE)

# Create Overview table for numeric variables
numeric.overview = data.frame(NACount = colSums(sapply(numeric.data, is.na)), LevelCount = sapply(numeric.data, 
    FUN = getlevelcount), Mode = sapply(numeric.data, FUN = getmode), ModeFrequency = sapply(numeric.data, 
    FUN = getmodefreq), Mean = sapply(numeric.data, FUN = meanwrapper), Median = sapply(numeric.data, 
    FUN = medianwrapper), SD = sapply(numeric.data, FUN = sdwrapper))
\end{lstlisting} 
Since both of these tables are very long we divide them into smaller tables of length 30 when saving them as latex files for including in this reports using multiple calls to the \textit{xtable} function from a loop:
\begin{lstlisting}[language=R]
# Export Categorical Overview as Latex Table
rows.per.table = 30
row.indices = seq(from = 1, to = nrow(numeric.overview), by = rows.per.table)
latex.vector = character(0)
for(i in 1:length(row.indices)){
    cap = paste0("Overview Numeric Variables Table:",i)
    lab = paste0("tab:numeric.overview",i)
    numeric.overview_latex = xtable(numeric.overview[row.indices[i]:min(row.indices[i] + rows.per.table - 1, nrow(numeric.overview)),,drop = FALSE], caption = cap, label =lab)
    latex.vector = c(latex.vector, print(numeric.overview_latex))
}
all.latex = paste(latex.vector, collapse = "\n")
writeLines(all.latex, con = "numeric_overview.tex")
\end{lstlisting} 


\subsubsection{Exploratory Data Analysis Dependence}
After investigating each variable on its own, it is very important to explore the dependency structure in the dataset. This is done in order to get an idea of how to use the available data in the models one is aiming for. For this project we implemented three functions. One creates a correlation plot, showing how strongly the numeric variables correlate with each other. The second function examines the relationship between the target variable \textit{SalePrice}. The third function creates boxplots of  the target variable for different levels of the categoric variables. 

The first function is called \textit{corr.func} and produces a correlation  plot giving the user some options on what the function output should contain.
\begin{lstlisting}[language=R]
corr.func = function(data, cut.value, corr.mat = FALSE, corr.test = FALSE, significance = 0.05) {
    corr.numeric = cor(na.omit(numeric.data))               # produces correlation matrix of all numeric variables in the dataset
    
    # find columns of data, which have correlations higher then cut.value
    find.rows = apply(corr.numeric, 1, function(x) sum(abs(x) > abs(cut.value)) > 1)
    
    # subset correlation matrix for plotting
    corr.numeric.adjusted = corr.numeric[find.rows, find.rows]
    
    # find data, which has low correlation
    low.corr = colnames(corr.numeric) %in% colnames(corr.numeric.adjusted)
    cat("The variables", "\n", paste0(colnames(corr.numeric)[!low.corr], collapse = ", "), "\n", "have very low bivariate correlations with the other numeric variables in the training data set!")
    
    # test correlations at certain significance level using a function, that produces a p-value matrix for all bivariate correlations
    correlation.test = function(corr.data) {
        corr.data            = as.matrix(corr.data)
        n                    = ncol(corr.data)
        p.value.matrix       = matrix(NA, n, n)
        diag(p.value.matrix) = 0
        
        for (i in 1:(n - 1)) {
            for (j in (i + 1):n) {
                tmp = cor.test(corr.data[, i], corr.data[, j])            # testing correlation
                p.value.matrix[i, j] = p.value.matrix[j, i] = tmp$p.value # filling p-value matrix with respective p-values
            }
            colnames(p.value.matrix) = rownames(p.value.matrix) = colnames(corr.numeric.adjusted)
        }
        return(p.value.matrix)
    }
    
    
    # save resulting correlation matrix
    pdf("Corrplot.pdf")
    if (corr.test == FALSE) {
        corrplot(corr.numeric.adjusted, method = "square", tl.col = "black")
    } else {
        corrplot(corr.numeric.adjusted, p.mat = correlation.test(corr.numeric.adjusted), sig.level = significance, 
            method = "square", tl.col = "black")
    }
    dev.off()
    
    # print raw correlation matrix if desired
    if (corr.mat == TRUE) 
        return(corr.numeric.adjusted)
}
\end{lstlisting}
The inputs of the function are \textit{data}, a \textit{cut.value} one has to choose, \textit{corr.mat} and \textit{corr.test} ,which both default to FALSE and \textit{significance}, which defaults to 0.05. The function first produces a correlation matrix of the numeric variables in the input data without missing values and uses this matrix to find the variables whose correlation with any other variable does not exceed the cutoff value set by the user using the \textit{apply} function. These variables are excluded from the final graph and are printed out to the user. Inside \textit{corr.func} there is another function called \textit{correlation.test}. This function uses the cutoff adjusted correlation matrix to produce p-values of a correlation test at the significance level chosen in the input of the main function. If the input \textit{corr.test} is used with its default value FALSE then a plain correlation plot is saved using the package \textit{corrplot}. Otherwise the p-value matrix from \textit{correlation.test} is shown in the plot via crosses indicating non-significance. Lastly if one chooses to set \textit{corr.mat} to TRUE, the raw correlation matrix is displayed. \\
The second function \textit{corr.barplot} focuses on the relationship between the target variable and all other numeric variables in the dataset. 
\begin{lstlisting}[language=R]
corr.barplot = function(numb.corr) {
    if (numb.corr > ncol(numeric.data) - 1) {
        return("Warning: You can choose at most all numeric variables in the dataset except the target variable SalePrice, which is already implemented as default value")
    } else {
        correlation.vars    = names(numeric.data) %in% c("SalePrice")
        correlation.data    = numeric.data[!correlation.vars]                  # subsetting the numeric variables to not contain the target variable
        correlations        = vector(length = length(names(correlation.data))) # setting up vector for results (correlations)
        names(correlations) = names(correlation.data)
        
        for (i in names(correlation.data)) {                                   # calculating all bivariate correlations
            correlations[i] = cor(numeric.data$SalePrice, correlation.data[i], use = "pairwise.complete.obs")
        }
        
        # setting up the results for plotting
        y.plotting = correlations[order(abs(correlations), decreasing = TRUE)][1:numb.corr]
        x.plotting = names(y.plotting)
        names(y.plotting) = NULL
        df = data.frame(x.plotting, y.plotting)
        df$x.plotting = factor(df$x.plotting, levels = df[order(abs(df$y.plotting), decreasing = TRUE), "x.plotting"])
        
        ggplot(data = df, aes(x.plotting, y.plotting), fill = as.factor(x.plotting)) + geom_bar(stat = "identity", color = "black", fill = "black") + 
            theme(panel.background = element_rect(fill = "white", colour = "black"),axis.title.x = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, size = 12)) + 
            ylab("Correlation") + ggtitle(paste("Barplot of the", numb.corr, "highest bivariate correlations with SalePrice", 
            sep = " "))
    }
}
\end{lstlisting}
The function \textit{corr.barplot} only has one input parameter \textit{numb.corr}, which sets the number of correlations to plot. If a number greater than the number of numeric variables other than the target variable is chosen a warning is returned. Otherwise the numeric data is split into the dependent variable and the rest. Afterwards all the correlations between \textit{SalePrice} and the other variables are calculated and stored. For plotting, only the \textit{numb.corr} number of variables with the highest absolute correlations are used. We use the package \textit{ggplot2} to create a barplot of the  correlations ordered by their absolute value. Calling the function therefore plots the resulting barplot directly in \textsf{R}. \\
The third function depicts the relationship between the target variable and categoric variables. 
\begin{lstlisting}[language=R]
boxplot.target = function(categoric) {
    if (class(data[, categoric]) != "factor") {
        return("The input variable has to be categorical. Numeric input does not work!")
    } else {
        # datapreparation for boxplots
        categoric.x = data[, categoric]
        plot.data = as.data.frame(cbind(data$SalePrice, categoric.x))
        plot.data[[2]] = as.factor(plot.data[[2]])
        levels(plot.data[[2]]) = levels(categoric.x)
        
        # creating the boxplot
        ggplot(plot.data, aes(x = categoric.x, y = V1)) + geom_boxplot() + labs(title = paste("Boxplots of SalePrice", 
            "\n", "depending on", categoric, sep = " "), x = categoric, y = "SalePrice") + theme_classic()
    }
}
\end{lstlisting}
The function \textit{boxplot.target} takes one input named \textit{categoric}, which is the data that is supposed to be used creating the boxplots. If the input variable is not categoric the function displays a warning, that numeric variables cannot be used within this function. \textit{Boxplot.target} prepares the data first, by creating a dataframe consisting of the dependent variable and the categoric variable chosen. Afterwards it produces boxplots of \textit{SalePrice} depending on each of the levels of the independent variable using \textit{ggplot2}.