\subsection{Data Preprocessing}

To  get an overview on the  the missing data the  function \textit{na.summary} returns variable names and the count of missing values for a given dataframe. 
For those factor variables where missing actually has a meaning, the function \textit{na2none} changes the missing value to a new level  "none". The function is than applied in a small loop to each variable of an earlier defined list (\textit{vars}). 

To visualize the remaining missings, a  missingnessplot  is created based on the package \textit{ggplot2}. For this, all variables with missing values are reshaped to a new dataframe that has three columns, such that for every combination of observation and variable the information is provided if there is a missing value or not. This is done conveniently with the \textit{reshape2} and \textit{dplyr} package.  
On the x-axis the variables are plotted, on the y axis the observation as ordered in the dataframe.

\begin{lstlisting}[language=R]
miss.plot = function(x) {
      x %>% is.na %>% melt 
      %>% ggplot(data = ., aes(x = Var2, y = Var1)) + geom_raster(aes(fill = value)) + 
            scale_fill_discrete(name = "", labels = c("Present", "Missing")) + theme_classic() + 
            theme(axis.text.x = element_text(angle = 45, vjust = 0.5)) + labs(x = "Variables in Dataset", 
            y = "Rows / observations")
}
\end{lstlisting}

For imputation purposes the dataframe is subsetted into numeric and categorical variables. 
Simple functions then calculate mode and median on the available data and replace the respective missing values.
For the mode, a small custom calculation function is needed in addition, because the base function in R does not work for non-numeric variables: 
\begin{lstlisting}[language=R]
Mode = function(x) {
      ux = unique(x)
      ux[which.max(tabulate(match(x, ux)))]
}
\end{lstlisting}
Using \textit{sapply} the median and mode functions are then applied on the respective subset of numeric and categorical variables. 

The function \textit{single.factors} then firstly calculates for every factor in a supplied dataframe the number of observations in each factor level. If there are equal or less than 20 observations in a level, the observations are reassigned to a category named "other". 
It is now possible that the factor level "other" still has less then 20 observations. To avoid that a variable now has only has one level and such a small "other" category (for example 1415 observations in one  factor level and 5 observations in the level "other"), the function  checks if there are only 2 factor levels and if one of these levels has less than 20 observations (because of the before implemented logic, this level can only be the level "other"). In this case, the value for all observations on that variable are set to \textit{NA} and the variable is then removed.

\begin{lstlisting}[language=R]
single.factors = function(data) {
      for (var in names(data)) {
            if (is.factor(data[[var]])) {
                  tbl = table(data[[var]])
                  ren = names(tbl)[tbl <= 20]
                  # rename all matching levels to other
                  levels(data[[var]])[levels(data[[var]]) %in% ren] = "Other"
                  # same procedure again, if now there is still a category with less than 20 it can only
                  # be other!
                  tbl     = table(data[[var]])
                  tbl_sum = sum(tbl < 20)
                  if (nlevels(data[[var]]) < 3 & tbl_sum >= 1) 
                        data[[var]] = NA
            }
      }
      return(data)
}
\end{lstlisting}


To get an overview of the number of outliers, the function \textit{outlier.count}  counts the numbers of outliers per variable.
It is now necessary to remove variables that only consist of "outliers", which is the case when the $IQR=0$. This situation occurs for instance, if a variable has zero for all but very few observations (e.g. number of bathrooms on the fifth floor). 

The function \textit{outlier.truncate} is very similar to \textit{outlier.count}, but also truncates the identified outliers to the IQR treshold as defined in part \nameref{sec:data_theory}. 

\begin{lstlisting}[language=R]
outlier.truncate = function(x) {
      low         = as.numeric(quantile(x)[2] - IQR(x) * 3)
      high        = as.numeric(IQR(x) * 3 + quantile(x)[4])
      x[x < low]  = low
      x[x > high] = high
      print(x)
      return(x)
}
\end{lstlisting}

For visualization purposes some boxplots are created, that show the difference in variables with more than 5 outliers before and after truncation. Another matrix of graphs is created for histograms of the processed numeric variables. 

The last step in the preprocessing is a PCA. To select appropriate variables only numeric variables that have an absolute correlation of more than 0.7 with at least one other variable are selected and assigned to the variable \textit{list}.  The PCA is then performed using the package \textit{princomp}.
To visualize the different PCA solutions, a screeplot  is created. The factor scores for the solution with four factors are extracted and assigned to the variable \textit{scores}. 

For further analysis, the different preprocessed dataframes (numeric variables, PCA-results and categorical variables) are then merged to a new dataframe and standardized where applicable. Using \textit{mode.matrix} the factor levels are converted to dummy variables. The final dataset is then split into test and training data and exported to .csv.
