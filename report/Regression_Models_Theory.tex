\subsection{Regression Models} \label{sec:reg_theory}
As it is well known from the Gauss-Markov (GM) theorem, there is no better linear unbiased estimator than the Ordinary Least Squares (OLS) estimator $\hat{\beta_{ols}} = (X'X)^{-1}X'Y$  if the conditions for GM are met (\cite{wooldridge_introductory_2015}). However, in the here considered scenario we have a large number of possible regressors given the number of observations. Thus, including all variables in an OLS model would likely lead to overfitting, where the model would fit well on the training data, but would not generalize well to other data, especially the test data it is later supposed to be applied on. In the worst case, perfect multicollinearity could occur (especially with regard to the dummy variables)  which means that some regressors are linear combinations of the other. In this case, the inverse of the matrix $(X'X)$ does not exist  because of singularity which means $\beta_{OLS}$ cannot be calculated.  
On the other hand, it is important to include all relevant variables, as one  might otherwise reduce the predictive capabilities of our model. 
While in econometric models  the selection of variables is usually based on theory, in the scenario of this Kaggle challenge we do not have theoretical assumptions about our dataset. Therefore an alternative procedure for variable selection is needed. The quantlet "Regression Models"  implements four regression based methods and tests them on the Ames housing data. 

\subsubsection{Backward Selection}
A straightforward variable selection approach is backwards stepwise regression. While there are several ways to implement this idea, one possibility is to  start with all variables (except those that are perfect linear combinations of others), and then eliminate insignificant variables based on a series of  t-tests. This procedure is repeated, until every variable is significant. The decision on the significance of a regressor is an arbitrary number. Here, we rely on a $\alpha = 0.05$ threshold, as it is a commonly used level in econometric applications. 

\subsubsection{Forward Selection}
The second implemented model is forward selection based on the AIC (Akaike Information Criterion). The AIC is defined as 
${\displaystyle \mathrm{AIC}=2k-2\ln({\hat{L}})}$, where $\hat{L}$ is the likelihood of a given model. The stepwise algorithm keeps adding variables until there is no further decrease in the AIC possible. This situation occurs, when the penalty term $2k$ exceeds the difference in likelihood resulting from the inclusion of further variables. 

\subsubsection{Ridge and Lasso Regression}
Ridge and Lasso regressions omit the assumption of an unbiased estimator. Both models include a penalizing term for the regressors, and therefore minimize the penalized sum of squares.  Written in a Lagrange - Multiplier form it is easy to see, that the only difference between both estimators is the $L^{p}$-norm: Ridge relies on an $L^{2}$-norm, while Lasso uses an  $L^{1}$-norm (\cite{friedman_elements_2001}, pp. 69ff).  

\begin{equation}
hat{\beta_{lasso}}=argmin\{\frac{1}{2}\sum_{t=1}^{N}(y_{t}-\beta_{0}-\sum_{j=1}^{p}x_{ij}\beta_{j})^{2}+\lambda\sum_{j=1}^{p}|\beta_{j}|\}
\end{equation}

\begin{equation}
hat{\beta_{ridge}}=argmin\{\frac{1}{2}\sum_{t=1}^{N}(y_{t}-\beta_{0}-\sum_{j=1}^{p}x_{ij}\beta_{j})^{2}+\lambda\sum_{j=1}^{p}\beta_{j}^{2}\}
\end{equation}

The different $L^{p}$ norm however leads to a different behavior in both models: Ridge's L2 penalty term only limits the size of the coefficient vector, a behavior that is referred to as shrinkage. Thus, Ridge will return the original number of variables.  Lasso on the other hand will also result in sparsity, which means that some coefficients will get the value zero and therefore drop out of the model. 

The question is now, how the hyperparameter $\lambda$ is chosen. We follow a cross validation approach, as it is common practice in machine learning. For this, a sequence of possible $\lambda$ values is tested on different splits  of the initial sample into training and test data.  We rely on  k-fold cross-validation, where the dataset is split in k folds, and then each split is used once as testing data for validation, while the remaining folds function as training data. 
Based on the Mean Squared Error (MSE), the optimal $\lambda$ parameter is then chosen. We use the first standard deviation of the $\lambda$, that yields the lowest MSE, as this leads to more robust results, since overfitting is avoided (the alternative is to use the  $\lambda$ with the smallest MSE itself, which might however generalize badly). 

It should be highlighted, that there is some criticism in the literature regarding the use of both stepwise as well as regularized models, especially that they should be avoided if there are theoretical assumptions about the data and the interest of an analysis lies in statistical inference. Since this is not the case and we are only concerned with the predictive performance of our models, the criticism can be relaxed in this particular analysis. 



