\subsection{Random Forest}
As a first alternative to the linear regression models we used a random forest regression from the \textit{randomForest} package. The main tuning parameter that controls the performance of the random forest regression is the called \textit{mtry} and controls the number of variables that are randomly chosen to grow each tree. To optimize over this parameter we use the \textit{caret} package. This package allows very easy tuning of metaparameters for a variety of models from numerous packages. In this package the main function that we use is the \textit{train} function. To train/tune the random forest model one simply calls this function and chooses the model to be used by passing the \textit{method} parameter as a string. For the random forest model from the above mentioned package the corresponding \textit{method} value is "rf". Except for the formula, data and method arguments the \textit{train} function also expects the argument \textit{trControl}. This argument needs to be a named list specifying the details of the training process. A list of this type can be created using the \textit{trainControl} function from the same package. In this case we use this function to choose repeated cross validation as evaluation method for each tuning parameter value and specify the number of folds, repeats and the training proportion in each split.  Another parameter that we need to pass for the tuning of the model is the tuning grid. For this we pass a vector of different values for each tuning variable to the \textit{expand.grid} function which then returns all combinations of parameter values to be tested in the tuning process. Since the \textit{caret} package only allows the tuning of the \textit{mtry} parameter for the random forest model our tuning grid is one dimensional and therefore just a list of values for this parameter. Apart from the easy implementation another advantage of using the \textit{caret} package is the fact that the tuning process can be parallelised very easily. For this we just need to create a cluster of cores using the \textit{makeCluster} function from the \textit{doParallel} package. In our implementation we use all but one core of the machine to enable the user to do other tasks while the model is running.

\begin{lstlisting}[language=R]
# Cross Validation Parameter
ptrain      = 0.85
nfolds      = 5
nrepeats    = 1
# Tuning Parameter Values for Random Forest
mtry.tuning = seq(from = 20, to = 160, by = 20)
# Parameter Tuning based on caret package Choose Valdation Method
CrossValidation = trainControl(method = "repeatedcv", number = nfolds, p = ptrain, repeats = nrepeats)
# Create Random Forest Tuning Grid:
rfGrid = expand.grid(mtry = mtry.tuning)
#Determine Number of Cores to use (All Cores but one)
cores       = max(c(detectCores() - 1, 1))
#Set Up Cluster for parallel processing
cl          = makeCluster(cores)
registerDoParallel(cl)
set.seed(123)
#Tune Model
rftuned = train(logSalePrice ~ ., data = df, method = "rf", importance = TRUE, trControl = CrossValidation, verbose = TRUE, 
    tuneGrid = rfGrid)
stopCluster(cl)
\end{lstlisting}